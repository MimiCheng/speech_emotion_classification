{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech emotion classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/mimi/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/mimi/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/mimi/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/mimi/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/mimi/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/mimi/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from numpy import concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create label by shifting 1 row\n",
    "def create_label(df):\n",
    "    df['id'] = df['_attribute_name_string'].astype(str).str[:2]\n",
    "    #shift time label\n",
    "    df['label'] = df.groupby(['id'])['emotion'].shift(-1)\n",
    "    return df\n",
    "\n",
    "# create timesteps\n",
    "def get_sup(data, timesteps):\n",
    "    raw_values = data.values\n",
    "    # transform data to be supervised learning\n",
    "    df = pd.DataFrame(data.values)\n",
    "    columns = [df.shift(-i) for i in range(1, timesteps+1)]\n",
    "    #convert list into dataframe\n",
    "    dataframe = concat(columns, axis=1)\n",
    "    #merge with the initial column\n",
    "    result = concat([df, dataframe], axis=1, sort=False)\n",
    "    supervised_values = result.values[:-timesteps,:]\n",
    "    return supervised_values \n",
    "\n",
    "# select features in dataframe\n",
    "def select_features(df, start_cols, end_cols, timesteps):\n",
    "    lst = []\n",
    "    for column in df.columns[start_cols:end_cols]:\n",
    "        lst.append(get_sup(df[column], timesteps))\n",
    "    return lst\n",
    "\n",
    "#reformat into timesteps and remove nan, the more timestep, the more data is removed.\n",
    "def re_format(a,b):\n",
    "    a = np.array(a)    \n",
    "    b = np.array(b)\n",
    "    b = b.reshape(b.shape[1], b.shape[2], b.shape[0])\n",
    "    \n",
    "    def no_nan(list_a):\n",
    "        return all(x == x for x in list_a) # oppsite of any(x!=x)\n",
    "\n",
    "    filtered = [no_nan(x) for x in a]\n",
    "    return np.array([y[-1] for y in a[filtered]]), b[filtered]\n",
    "\n",
    " # fit an LSTM network to training data\n",
    "def fit_lstm(X, y, batch_size, nb_epoch, neurons):\n",
    "    model = Sequential()\n",
    "    print(f\"Batch size: {batch_size}, Timesteps: {X.shape[1]}, Features: {X.shape[2]}\")\n",
    "    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    for i in range(nb_epoch):\n",
    "        # if don't want to show training stages, set verbose=0\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=1, shuffle=False)\n",
    "        model.reset_states()\n",
    "    return model\n",
    "\n",
    "# validate data by average precision_score, can be changed depends on use cases\n",
    "def predictor(model, batch_size, X, y):\n",
    "    yhat = model.predict(X, batch_size=batch_size)\n",
    "    average_precision = average_precision_score(y, yhat)\n",
    "    return average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # for demo, I selected only 4 features \n",
    "    start_cols = 2\n",
    "    end_cols = 6\n",
    "\n",
    "    #model hyperparameters\n",
    "    timesteps = 2 # starts from 0\n",
    "    batch_size = 2\n",
    "    epochs = 100\n",
    "    neurons = 2\n",
    "    \n",
    "    df = pd.read_csv('speech_extracted_sample.csv')\n",
    "    # data preprocessing\n",
    "    prep_df = create_label(df)\n",
    "    y1 = get_sup(prep_df['label'], timesteps)\n",
    "    x1s = select_features(prep_df, start_cols, end_cols, timesteps)\n",
    "    y_all, x_all = re_format(y1, x1s)\n",
    "    # train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.3, random_state=42)\n",
    "    # model fitting\n",
    "    model = fit_lstm(X_train, y_train, batch_size, epochs, neurons)\n",
    "    # forecasting\n",
    "    average_precision = predictor(model, batch_size, X_test, y_test)\n",
    "    print(f\"average precision score: {average_precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 2, Timesteps: 3, Features: 4\n",
      "WARNING:tensorflow:From /Users/mimi/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/mimi/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.4854\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 815us/step - loss: 0.3480\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 749us/step - loss: 0.2607\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 734us/step - loss: 0.2090\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 734us/step - loss: 0.1770\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 722us/step - loss: 0.1560\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 729us/step - loss: 0.1418\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 769us/step - loss: 0.1317\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 739us/step - loss: 0.1243\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 758us/step - loss: 0.1189\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 740us/step - loss: 0.1147\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 732us/step - loss: 0.1115\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 733us/step - loss: 0.1089\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 763us/step - loss: 0.1069\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 748us/step - loss: 0.1052\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 767us/step - loss: 0.1039\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 751us/step - loss: 0.1028\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 772us/step - loss: 0.1019\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 781us/step - loss: 0.1011\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 744us/step - loss: 0.1005\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 740us/step - loss: 0.0999\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 771us/step - loss: 0.0994\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 742us/step - loss: 0.0991\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 745us/step - loss: 0.0987\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 783us/step - loss: 0.0984\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 755us/step - loss: 0.0982\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 750us/step - loss: 0.0980\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 749us/step - loss: 0.0978\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 756us/step - loss: 0.0976\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 753us/step - loss: 0.0975\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 752us/step - loss: 0.0973\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 751us/step - loss: 0.0972\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 776us/step - loss: 0.0971\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 743us/step - loss: 0.0970\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 759us/step - loss: 0.0970\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 766us/step - loss: 0.0969\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 803us/step - loss: 0.0968\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 891us/step - loss: 0.0968\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 829us/step - loss: 0.0967\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 746us/step - loss: 0.0967\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 770us/step - loss: 0.0967\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 744us/step - loss: 0.0966\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 764us/step - loss: 0.0966\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 774us/step - loss: 0.0966\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 817us/step - loss: 0.0965\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 761us/step - loss: 0.0965\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 748us/step - loss: 0.0965\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 750us/step - loss: 0.0965\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 872us/step - loss: 0.0965\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 805us/step - loss: 0.0964\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 818us/step - loss: 0.0964\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 784us/step - loss: 0.0964\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 801us/step - loss: 0.0964\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 821us/step - loss: 0.0964\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 912us/step - loss: 0.0964\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 778us/step - loss: 0.0964\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 880us/step - loss: 0.0964\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 818us/step - loss: 0.0964\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 757us/step - loss: 0.0963\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 797us/step - loss: 0.0963\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 749us/step - loss: 0.0963\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 785us/step - loss: 0.0963\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 834us/step - loss: 0.0963\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 795us/step - loss: 0.0963\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 834us/step - loss: 0.0963\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 785us/step - loss: 0.0963\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 777us/step - loss: 0.0963\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 779us/step - loss: 0.0963\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 772us/step - loss: 0.0963\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 779us/step - loss: 0.0963\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 773us/step - loss: 0.0963\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 770us/step - loss: 0.0963\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 811us/step - loss: 0.0962\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 787us/step - loss: 0.0962\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 816us/step - loss: 0.0962\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 779us/step - loss: 0.0962\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 767us/step - loss: 0.0962\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 772us/step - loss: 0.0962\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 802us/step - loss: 0.0962\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 789us/step - loss: 0.0962\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 756us/step - loss: 0.0962\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 863us/step - loss: 0.0962\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 816us/step - loss: 0.0962\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 802us/step - loss: 0.0962\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 801us/step - loss: 0.0962\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 795us/step - loss: 0.0962\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 858us/step - loss: 0.0962\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 803us/step - loss: 0.0962\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 808us/step - loss: 0.0962\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 813us/step - loss: 0.0962\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 806us/step - loss: 0.0962\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 855us/step - loss: 0.0961\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 795us/step - loss: 0.0961\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 759us/step - loss: 0.0961\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 781us/step - loss: 0.0961\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 831us/step - loss: 0.0961\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 865us/step - loss: 0.0961\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 780us/step - loss: 0.0961\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 802us/step - loss: 0.0961\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 816us/step - loss: 0.0961\n",
      "average precision score: 0.9837223751467024\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
